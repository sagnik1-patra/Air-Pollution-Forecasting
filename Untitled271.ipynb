{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d55c3acc-9131-4794-a5a6-ec890eb7c2fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\NXTWAVE\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "[INFO] Loading datasets...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NXTWAVE\\AppData\\Local\\Temp\\ipykernel_21644\\3662021746.py:33: DtypeWarning: Columns (15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_hour_station = pd.read_csv(FILES[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Preprocessing data...\n",
      "[INFO] Building model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NXTWAVE\\AppData\\Local\\Temp\\ipykernel_21644\\3662021746.py:48: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df = df.fillna(method='ffill').fillna(method='bfill')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\NXTWAVE\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\NXTWAVE\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:6642: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\NXTWAVE\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 10, 64)            256       \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1  (None, 5, 64)             0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 64)                33024     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                2080      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 32)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 35393 (138.25 KB)\n",
      "Trainable params: 35393 (138.25 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "[INFO] Training model...\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:From C:\\Users\\NXTWAVE\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\NXTWAVE\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "2161/2161 [==============================] - 14s 5ms/step - loss: 0.0022 - mae: 0.0283 - val_loss: 0.0017 - val_mae: 0.0234\n",
      "Epoch 2/50\n",
      "2161/2161 [==============================] - 10s 5ms/step - loss: 0.0017 - mae: 0.0245 - val_loss: 0.0017 - val_mae: 0.0235\n",
      "Epoch 3/50\n",
      "2161/2161 [==============================] - 11s 5ms/step - loss: 0.0016 - mae: 0.0238 - val_loss: 0.0015 - val_mae: 0.0213\n",
      "Epoch 4/50\n",
      "2161/2161 [==============================] - 10s 5ms/step - loss: 0.0015 - mae: 0.0234 - val_loss: 0.0015 - val_mae: 0.0220\n",
      "Epoch 5/50\n",
      "2161/2161 [==============================] - 10s 4ms/step - loss: 0.0014 - mae: 0.0228 - val_loss: 0.0014 - val_mae: 0.0210\n",
      "Epoch 6/50\n",
      "2161/2161 [==============================] - 10s 4ms/step - loss: 0.0014 - mae: 0.0223 - val_loss: 0.0013 - val_mae: 0.0205\n",
      "Epoch 7/50\n",
      "2161/2161 [==============================] - 10s 4ms/step - loss: 0.0013 - mae: 0.0220 - val_loss: 0.0013 - val_mae: 0.0207\n",
      "Epoch 8/50\n",
      "2161/2161 [==============================] - 11s 5ms/step - loss: 0.0013 - mae: 0.0216 - val_loss: 0.0016 - val_mae: 0.0240\n",
      "Epoch 9/50\n",
      "2161/2161 [==============================] - 11s 5ms/step - loss: 0.0013 - mae: 0.0215 - val_loss: 0.0012 - val_mae: 0.0197\n",
      "Epoch 10/50\n",
      "2161/2161 [==============================] - 11s 5ms/step - loss: 0.0013 - mae: 0.0211 - val_loss: 0.0012 - val_mae: 0.0197\n",
      "Epoch 11/50\n",
      "2161/2161 [==============================] - 11s 5ms/step - loss: 0.0012 - mae: 0.0210 - val_loss: 0.0012 - val_mae: 0.0191\n",
      "Epoch 12/50\n",
      "2161/2161 [==============================] - 11s 5ms/step - loss: 0.0012 - mae: 0.0207 - val_loss: 0.0012 - val_mae: 0.0196\n",
      "Epoch 13/50\n",
      "2161/2161 [==============================] - 11s 5ms/step - loss: 0.0012 - mae: 0.0207 - val_loss: 0.0011 - val_mae: 0.0189\n",
      "Epoch 14/50\n",
      "2161/2161 [==============================] - 11s 5ms/step - loss: 0.0012 - mae: 0.0206 - val_loss: 0.0011 - val_mae: 0.0189\n",
      "Epoch 15/50\n",
      "2161/2161 [==============================] - 11s 5ms/step - loss: 0.0012 - mae: 0.0205 - val_loss: 0.0012 - val_mae: 0.0197\n",
      "Epoch 16/50\n",
      "2161/2161 [==============================] - 12s 6ms/step - loss: 0.0012 - mae: 0.0204 - val_loss: 0.0011 - val_mae: 0.0185\n",
      "Epoch 17/50\n",
      "2161/2161 [==============================] - 12s 6ms/step - loss: 0.0011 - mae: 0.0202 - val_loss: 0.0011 - val_mae: 0.0193\n",
      "Epoch 18/50\n",
      "2161/2161 [==============================] - 11s 5ms/step - loss: 0.0011 - mae: 0.0201 - val_loss: 0.0011 - val_mae: 0.0184\n",
      "Epoch 19/50\n",
      "2161/2161 [==============================] - 11s 5ms/step - loss: 0.0011 - mae: 0.0201 - val_loss: 0.0012 - val_mae: 0.0186\n",
      "Epoch 20/50\n",
      "2161/2161 [==============================] - 12s 5ms/step - loss: 0.0011 - mae: 0.0200 - val_loss: 0.0011 - val_mae: 0.0186\n",
      "Epoch 21/50\n",
      "2161/2161 [==============================] - 11s 5ms/step - loss: 0.0011 - mae: 0.0198 - val_loss: 0.0011 - val_mae: 0.0184\n",
      "Epoch 22/50\n",
      "2161/2161 [==============================] - 11s 5ms/step - loss: 0.0011 - mae: 0.0198 - val_loss: 0.0010 - val_mae: 0.0178\n",
      "Epoch 23/50\n",
      "2161/2161 [==============================] - 11s 5ms/step - loss: 0.0011 - mae: 0.0197 - val_loss: 0.0010 - val_mae: 0.0177\n",
      "Epoch 24/50\n",
      "2161/2161 [==============================] - 11s 5ms/step - loss: 0.0011 - mae: 0.0196 - val_loss: 0.0011 - val_mae: 0.0202\n",
      "Epoch 25/50\n",
      "2161/2161 [==============================] - 11s 5ms/step - loss: 0.0011 - mae: 0.0195 - val_loss: 0.0011 - val_mae: 0.0182\n",
      "Epoch 26/50\n",
      "2161/2161 [==============================] - 11s 5ms/step - loss: 0.0011 - mae: 0.0196 - val_loss: 0.0010 - val_mae: 0.0180\n",
      "Epoch 27/50\n",
      "2161/2161 [==============================] - 12s 5ms/step - loss: 0.0010 - mae: 0.0194 - val_loss: 0.0011 - val_mae: 0.0184\n",
      "Epoch 28/50\n",
      "2161/2161 [==============================] - 11s 5ms/step - loss: 0.0010 - mae: 0.0193 - val_loss: 0.0011 - val_mae: 0.0194\n",
      "Epoch 29/50\n",
      "2161/2161 [==============================] - 11s 5ms/step - loss: 0.0010 - mae: 0.0191 - val_loss: 0.0010 - val_mae: 0.0177\n",
      "Epoch 30/50\n",
      "2161/2161 [==============================] - 11s 5ms/step - loss: 0.0010 - mae: 0.0191 - val_loss: 0.0011 - val_mae: 0.0185\n",
      "Epoch 31/50\n",
      "2161/2161 [==============================] - 11s 5ms/step - loss: 9.9956e-04 - mae: 0.0190 - val_loss: 0.0010 - val_mae: 0.0179\n",
      "Epoch 32/50\n",
      "2161/2161 [==============================] - 12s 5ms/step - loss: 9.6901e-04 - mae: 0.0187 - val_loss: 0.0011 - val_mae: 0.0175\n",
      "Epoch 33/50\n",
      "2161/2161 [==============================] - 11s 5ms/step - loss: 9.7588e-04 - mae: 0.0188 - val_loss: 9.8210e-04 - val_mae: 0.0171\n",
      "Epoch 34/50\n",
      "2161/2161 [==============================] - 11s 5ms/step - loss: 9.6917e-04 - mae: 0.0187 - val_loss: 9.7224e-04 - val_mae: 0.0171\n",
      "Epoch 35/50\n",
      "2161/2161 [==============================] - 12s 5ms/step - loss: 9.5454e-04 - mae: 0.0186 - val_loss: 9.5467e-04 - val_mae: 0.0167\n",
      "Epoch 36/50\n",
      "2161/2161 [==============================] - 12s 5ms/step - loss: 9.6722e-04 - mae: 0.0186 - val_loss: 0.0010 - val_mae: 0.0174\n",
      "Epoch 37/50\n",
      "2161/2161 [==============================] - 11s 5ms/step - loss: 9.5095e-04 - mae: 0.0184 - val_loss: 9.9135e-04 - val_mae: 0.0168\n",
      "Epoch 38/50\n",
      "2161/2161 [==============================] - 13s 6ms/step - loss: 9.4585e-04 - mae: 0.0185 - val_loss: 9.8457e-04 - val_mae: 0.0166\n",
      "Epoch 39/50\n",
      "2161/2161 [==============================] - 11s 5ms/step - loss: 9.3006e-04 - mae: 0.0183 - val_loss: 0.0010 - val_mae: 0.0176\n",
      "Epoch 40/50\n",
      "2161/2161 [==============================] - 11s 5ms/step - loss: 9.2708e-04 - mae: 0.0183 - val_loss: 9.6027e-04 - val_mae: 0.0168\n",
      "Epoch 41/50\n",
      "2161/2161 [==============================] - 11s 5ms/step - loss: 9.2592e-04 - mae: 0.0183 - val_loss: 0.0010 - val_mae: 0.0169\n",
      "Epoch 42/50\n",
      "2161/2161 [==============================] - 11s 5ms/step - loss: 9.1292e-04 - mae: 0.0181 - val_loss: 9.7412e-04 - val_mae: 0.0167\n",
      "Epoch 43/50\n",
      "2161/2161 [==============================] - 12s 5ms/step - loss: 9.1905e-04 - mae: 0.0181 - val_loss: 0.0011 - val_mae: 0.0189\n",
      "Epoch 44/50\n",
      "2161/2161 [==============================] - 12s 5ms/step - loss: 9.0680e-04 - mae: 0.0180 - val_loss: 9.8483e-04 - val_mae: 0.0168\n",
      "Epoch 45/50\n",
      "2161/2161 [==============================] - 13s 6ms/step - loss: 9.0035e-04 - mae: 0.0180 - val_loss: 0.0010 - val_mae: 0.0171\n",
      "[INFO] Evaluating model...\n",
      "676/676 [==============================] - 2s 2ms/step\n",
      "{\n",
      "    \"MAE\": 0.016435082959576124,\n",
      "    \"RMSE\": 0.02911214520874946,\n",
      "    \"R2\": 0.8534166800856454\n",
      "}\n",
      "[INFO] Saving model and results...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NXTWAVE\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[‚úÖ] All files saved successfully at:\n",
      "C:\\Users\\NXTWAVE\\Downloads\\Air Pollution Forecasting\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "import pickle\n",
    "import yaml\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Conv1D, MaxPooling1D, Flatten, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# ================================================================\n",
    "# üìÇ PATHS\n",
    "# ================================================================\n",
    "BASE = r\"C:\\Users\\NXTWAVE\\Downloads\\Air Pollution Forecasting\"\n",
    "FILES = [\n",
    "    os.path.join(BASE, \"archive\", \"station_hour.csv\"),\n",
    "    os.path.join(BASE, \"archive\", \"stations.csv\"),\n",
    "    os.path.join(BASE, \"archive\", \"city_hour.csv\"),\n",
    "    os.path.join(BASE, \"archive\", \"station_day.csv\"),\n",
    "    os.path.join(BASE, \"archive\", \"city_day.csv\"),\n",
    "]\n",
    "\n",
    "# ================================================================\n",
    "# üìò LOAD AND MERGE DATA\n",
    "# ================================================================\n",
    "print(\"[INFO] Loading datasets...\")\n",
    "df_hour_station = pd.read_csv(FILES[0])\n",
    "df_stations = pd.read_csv(FILES[1])\n",
    "df_hour_city = pd.read_csv(FILES[2])\n",
    "df_day_station = pd.read_csv(FILES[3])\n",
    "df_day_city = pd.read_csv(FILES[4])\n",
    "\n",
    "# Use station_day as primary data (aggregated, less noisy)\n",
    "df = df_day_station.copy()\n",
    "\n",
    "# ================================================================\n",
    "# üßπ DATA PREPROCESSING\n",
    "# ================================================================\n",
    "print(\"[INFO] Preprocessing data...\")\n",
    "\n",
    "# Handle missing values\n",
    "df = df.fillna(method='ffill').fillna(method='bfill')\n",
    "\n",
    "# Drop unnecessary columns if exist\n",
    "drop_cols = ['station_id', 'station_name', 'Unnamed: 0']\n",
    "for c in drop_cols:\n",
    "    if c in df.columns:\n",
    "        df.drop(c, axis=1, inplace=True, errors='ignore')\n",
    "\n",
    "# Ensure numeric\n",
    "df = df.select_dtypes(include=[np.number])\n",
    "\n",
    "# Target variable\n",
    "target_col = 'PM2.5' if 'PM2.5' in df.columns else df.columns[-1]\n",
    "X = df.drop(columns=[target_col])\n",
    "y = df[target_col]\n",
    "\n",
    "# Normalize\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "y_scaled = scaler.fit_transform(y.values.reshape(-1, 1))\n",
    "\n",
    "# Reshape for CNN + LSTM\n",
    "X_scaled = X_scaled.reshape(X_scaled.shape[0], X_scaled.shape[1], 1)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_scaled, test_size=0.2, random_state=42)\n",
    "\n",
    "# ================================================================\n",
    "# üß† MODEL ARCHITECTURE (CNN + LSTM)\n",
    "# ================================================================\n",
    "print(\"[INFO] Building model...\")\n",
    "\n",
    "model = Sequential([\n",
    "    Conv1D(64, kernel_size=3, activation='relu', input_shape=(X_train.shape[1], 1)),\n",
    "    MaxPooling1D(2),\n",
    "    LSTM(64, return_sequences=False),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "model.summary()\n",
    "\n",
    "# ================================================================\n",
    "# üèãÔ∏è TRAINING\n",
    "# ================================================================\n",
    "print(\"[INFO] Training model...\")\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=32,\n",
    "                    validation_split=0.2, callbacks=[early_stop], verbose=1)\n",
    "\n",
    "# ================================================================\n",
    "# üìä EVALUATION\n",
    "# ================================================================\n",
    "print(\"[INFO] Evaluating model...\")\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "results = {\n",
    "    \"MAE\": float(mae),\n",
    "    \"RMSE\": float(rmse),\n",
    "    \"R2\": float(r2),\n",
    "}\n",
    "\n",
    "print(json.dumps(results, indent=4))\n",
    "\n",
    "# ================================================================\n",
    "# üíæ SAVE ARTIFACTS\n",
    "# ================================================================\n",
    "print(\"[INFO] Saving model and results...\")\n",
    "\n",
    "os.makedirs(BASE, exist_ok=True)\n",
    "model.save(os.path.join(BASE, \"hybrid_air_forecasting_model.h5\"))\n",
    "\n",
    "# Save results JSON\n",
    "with open(os.path.join(BASE, \"hybrid_air_forecasting_results.json\"), \"w\") as f:\n",
    "    json.dump(results, f, indent=4)\n",
    "\n",
    "# Save YAML\n",
    "with open(os.path.join(BASE, \"hybrid_air_forecasting_config.yaml\"), \"w\") as f:\n",
    "    yaml.dump({\"model\": \"CNN+LSTM\", \"optimizer\": \"adam\", \"epochs\": 50, \"batch_size\": 32}, f)\n",
    "\n",
    "# Save Pickle\n",
    "with open(os.path.join(BASE, \"hybrid_air_forecasting_scaler.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(scaler, f)\n",
    "\n",
    "# ================================================================\n",
    "# üìâ VISUALIZATIONS\n",
    "# ================================================================\n",
    "\n",
    "# Accuracy / Loss Curves\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "plt.title('Training vs Validation Loss')\n",
    "plt.xlabel('Epochs'); plt.ylabel('MSE')\n",
    "plt.legend()\n",
    "plt.savefig(os.path.join(BASE, \"hybrid_air_forecasting_loss_graph.png\"))\n",
    "plt.close()\n",
    "\n",
    "# Predicted vs Actual\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.scatter(y_test, y_pred, color='blue', alpha=0.6)\n",
    "plt.xlabel('Actual PM2.5'); plt.ylabel('Predicted PM2.5')\n",
    "plt.title('Prediction vs Actual')\n",
    "plt.savefig(os.path.join(BASE, \"hybrid_air_forecasting_prediction_graph.png\"))\n",
    "plt.close()\n",
    "\n",
    "# Correlation Heatmap\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(df.corr(), annot=False, cmap='coolwarm')\n",
    "plt.title('Feature Correlation Heatmap')\n",
    "plt.savefig(os.path.join(BASE, \"hybrid_air_forecasting_heatmap.png\"))\n",
    "plt.close()\n",
    "\n",
    "# Comparison Graph\n",
    "labels = list(results.keys())\n",
    "values = list(results.values())\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.bar(labels, values, color=['skyblue','lightgreen','salmon'])\n",
    "plt.title('Hybrid Model Performance Metrics')\n",
    "plt.savefig(os.path.join(BASE, \"hybrid_air_forecasting_comparison_graph.png\"))\n",
    "plt.close()\n",
    "\n",
    "print(\"[‚úÖ] All files saved successfully at:\")\n",
    "print(BASE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7fd1219-2811-41c0-b018-17338eaa3c32",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
